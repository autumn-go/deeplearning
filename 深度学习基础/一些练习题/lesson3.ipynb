{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "这节课就直接放答案了，大家看看就好，最好的工具还是到官网教程看下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch入门教程推荐官网一小时入门：https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简答题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Tensorflow中的计算图Graph指的是什么？\n",
    "> [参考](http://www.tensorfly.cn/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensorflow  \n",
    "\n",
    "TensorFlow 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。\n",
    "\n",
    "* 数据流图（Data Flow Graph）  \n",
    "\n",
    "数据流图用“结点”（nodes）和“线”(edges)的有向图来描述数学计算。“节点” 一般用来表示施加的数学操作，但也可以表示数据输入（feed in）的起点/输出（push out）的终点，或者是读取/写入持久变量（persistent variable）的终点。“线”表示“节点”之间的输入/输出关系。这些数据“线”可以输运“size可动态调整”的多维数据数组，即“张量”（tensor）。张量从图中流过的直观图像是这个工具取名为“Tensorflow”的原因。一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Tensorflow中的Operation指的是什么？边指的又是什么？\n",
    "> [参考]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Operation表示一种符号化的运算过程，是TensorFlow中的基本单元，即图中的节点。它的输入和输出都是Tensor  \n",
    "\n",
    "* 边指的是“张量”（tensor）,表示“节点”之间的输入/输出关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Tensorflow中的Session是如何使用？\n",
    "> [参考](https://blog.csdn.net/hongxue8888/article/details/76762108)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow中的会话(Session)是来执行定义好的运算的。会话拥有并管理Tensorflow程序运行时的所有资源, 提供了Operation执行和Tensor求值的环境\n",
    "\n",
    "Tensorflow中使用会话的模式一般有两种\n",
    "    * 第一种模式需要明确调用会话生成函数和关闭会话函数\n",
    "> 使用这种模式时，所有计算完成后，需要明确调用Session.close()函数关闭会话并释放资源。然而当程序因为异常而退出时，关闭会话的函数可能就不会被执行而导致资源泄露。\n",
    "\n",
    "    * 第二种模式通过Python的上下文管理器来使用会话  \n",
    "> 通过Python上下文管理器的机制，只要将所有的计算放在with的内部就可以。当上下文管理器退出时就会自动释放所有资源。这样既解决了因为异常退出时资源释放的问题，同时也解决了忘记调用Session.close函数而产生的资源泄露。  \n",
    "\n",
    "    * （附加分)在交互式环境下直接构建默认会话函数  \n",
    "    \n",
    "> 在交互式环境下（比如Python脚本 IPython 或者Jupyter的编辑器下），通过设置默认会话的方式来获取张量的取值更加方便。所以TensorFlow提供了tf.InteractiveSession函数，可以在交互式环境下直接构建默认会话。这个函数会自动将生成的会话注册为默认会话。使用 Tensor.eval() 和 Operation.run() 方法代替 Session.run(). 这样可以避免使用一个变量来持有会话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Tensorflow用什么方法中来实现模型初始化？\n",
    "> [参考](https://blog.csdn.net/zlrai5895/article/details/80550924)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量的初始化必须在模型的其它操作运行之前先明确地完成。最简单的方法就是添加一个给所有变量初始化的操作，并在使用模型之前首先运行那个操作。\n",
    "\n",
    "tensorflow模型初始化的方法有：   \n",
    "（1）初始化为常量：tf.constant_initializer(value)  \n",
    "（2）初始化为正太分布： tf.random_normal_initializer()、 tf.truncated_normal_initializer()   \n",
    "（3）初始化为均匀分布：tf.random_uniform_initializer()   \n",
    "（4）初始化为变尺度正太均匀分布：tf.variance_scaling_initializer()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Tensorflow中如何在模型的训练过程进行保存，以及载入一个训练好的模型？\n",
    "> [参考](https://blog.csdn.net/huachao1001/article/details/78501928)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型训练过程进行保存  \n",
    "在使用tf来训练模型的时候，难免会出现中断的情况。这时候自然就希望能够将辛辛苦苦得到的中间参数保留下来，不然下次又要重新开始。好在tf官方提供了保存和读取模型的方法。  \n",
    "\n",
    "```\n",
    "# 之前是各种构建模型graph的操作(矩阵相乘，sigmoid等等....)\n",
    "\n",
    "saver = tf.train.Saver() # 生成saver\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 先对模型初始化\n",
    "\n",
    "    # 然后将数据丢入模型进行训练blablabla\n",
    "\n",
    "    # 训练完以后，使用saver.save 来保存\n",
    "    saver.save(sess, \"save_path/file_name\") #file_name如果不存在的话，会自动创建\n",
    "```  \n",
    "\n",
    "* 载入一个训练好的模型  \n",
    "\n",
    "```\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的值给覆盖\n",
    "    sess.run(tf.global_variables_initializer())     \n",
    "    saver.restore(sess, \"save_path/file_name\") #会将已经保存的变量值resotre到 变量中。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Tensorflow中的PlaceHolder的意义在哪？\n",
    "> [参考](https://blog.csdn.net/mwlwlm/article/details/71541300)  \n",
    "> [参考](https://blog.csdn.net/allenlzcoder/article/details/78112765)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "占位符,此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值，placeholder相当于定义了一个位置，这个位置中的数据在程序运行时再指定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.请解读TensorBoard可以在哪些方面配合模型的训练？\n",
    "> [参考](https://blog.csdn.net/jiandanjinxin/article/details/77155565?locationnum=9&fps=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard 是 TensorFlow 上一个非常酷的功能，神经网络很多时候就像是个黑盒子，里面到底是什么样，是什么样的结构，是怎么训练的，可能很难搞清楚。而 TensorBoard 的作用就是可以把复杂的神经网络训练过程给可视化，可以更好地理解，调试并优化程序。   \n",
    "TensorBoard可以将训练过程中的各种绘制数据展示出来，包括标量（scalars），图片（images），音频（Audio）,计算图（graph）,数据分布，直方图（histograms）和嵌入式向量。  \n",
    "\n",
    "* 在 scalars 下可以看到 accuracy，cross entropy，dropout，layer1 和 layer2 的 bias 和 weights 等的趋势。\n",
    "* 在 images 和 audio 下可以看到输入的数据。展示训练过程中记录的图像和音频。\n",
    "* 在 graphs 中可以看到模型的结构。\n",
    "* 在 histogram 可以看到 activations，gradients 或者 weights 等变量的每一步的分布，越靠前面就是越新的步数的结果。展示训练过程中记录的数据的分布图\n",
    "* distribution 和 histogram 是两种不同的形式，可以看到整体的状况。\n",
    "* 在 embedding 中可以看到用 PCA 主成分分析方法将高维数据投影到 3D 空间后的数据的关系。\n",
    "* Event: 展示训练过程中的统计数据（最值，均值等）变化情况"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
