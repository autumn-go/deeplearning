{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简答题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.请解释下CNN网络中权值共享与稀疏交互的特性及作用？\n",
    "> [参考:权值共享](https://www.cnblogs.com/bonelee/p/8242061.html)  \n",
    "> [参考:稀疏交互](https://www.cnblogs.com/bonelee/p/8242061.html)  \n",
    "> <font color=red>评分标准: 能点中降低计算时间复杂度即给分,能让评分者清晰明了满分<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CNN网络中权值共享  \n",
    "\n",
    "权值共享:具体做法是，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6(该值可变)个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核(也称滤波器)的大小）  \n",
    "\n",
    "* CNN网络中稀疏交互  \n",
    "\n",
    "稀疏连接（Sparse Connectivity），又称稀疏交互、稀疏权重。受神经科学中每个细胞只对一个视觉区域内极小的一部分敏感，而对其他部分则可以视而不见的现象启发，稀疏连接成为卷积神经网络的一种重要思想，以帮助改进机器学习系统。  \n",
    "\n",
    "稀疏交互: 相比于全连接神经网络，CNN每一层的权重要稀疏很多，卷积核只与在其感受野范围内的输入单元产生交互，随着卷积核的滑动完成特征的检测。与原来每个输入单元都与输出单元交互相比，计算时间复杂度降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.卷积网络有哪些池化操作，其作用又是什么？\n",
    "> [参考](https://blog.csdn.net/u011734144/article/details/80137049)  \n",
    "> <font color=red>评分标准: 能答出一般池化的两种计量方式即给满分<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 池化层  \n",
    "\n",
    "池化层往往在卷积层后面，通过池化来降低卷积层输出的特征向量，同时改善结果（不易出现过拟合）。  \n",
    "\n",
    "    * 为什么可以通过降低维度呢？\n",
    "        \n",
    "      因为图像具有一种“静态性”的属性，这也就意味着在一个图像区域有用的特征极有可能在另一个区域同样适用。因此，为了描述大的图像，一个很自然的想法就是对不同位置的特征进行聚合统计，例如，人们可以计算图像一个区域上的某个特定特征的平均值 (或最大值)来代表这个区域的特征。\n",
    "\n",
    "*  一般池化（General Pooling）  \n",
    "\n",
    "池化作用于图像中不重合的区域（这与卷积操作不同）  \n",
    "最常见的池化操作为平均池化mean pooling和最大池化max pooling：\n",
    "\n",
    "    * 平均池化：计算图像区域的平均值作为该区域池化后的值。\n",
    "\n",
    "    * 最大池化：选图像区域的最大值作为该区域池化后的值。\n",
    "\n",
    "*  重叠池化（OverlappingPooling）  \n",
    "\n",
    "重叠池化正如其名字所说的，相邻池化窗口之间会有重叠区域  \n",
    "\n",
    "* 空间字塔池化（Spatial Pyramid Pooling）  \n",
    "\n",
    "空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义。 \n",
    "\n",
    "一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.数据归一化在深度学习中的意义是什么？\n",
    "> [参考](https://blog.csdn.net/CSDN_Black/article/details/81014781)  \n",
    "> <font color=red>评分标准: 能答出加速收敛或相关信息,即给满分<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 取消量纲 使得剃度始终朝着最小值的方向前进 少走弯路 加速收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.DropOut具体做了什么使得其能够降低模型的过拟合?\n",
    "> [参考](https://blog.csdn.net/garfielder007/article/details/51038544)  \n",
    "> <font color=red>评分标准: 能答出训练过程中,下一层的神经元以某一概率被舍弃即可满分<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化方法是通过修改损失函数来提高过拟合能力的，而dropout是通过改变网络的结构来提高的，这是和正则化方法最本质的区别\n",
    "\n",
    "dropout的提出是为了防止在训练过程中的过拟合现象，那就有人想了，能不能对每一个输入样本训练一个模型，然后在test阶段将每个模型取均值，这样通过所有模型共同作用，可以将样本最有用的信息提取出来，而把一些噪声过滤掉。\n",
    "\n",
    "那如何来实现这种想法呢？在每一轮训练过程中，我们对隐含层的每个神经元以一定的概率p舍弃掉，这样相当于每一个样本都训练出一个模型。假设有H个神经元，那么就有2H种可能性，对应2H模型，训练起来时间复杂度太高。我们通过权重\n",
    "\n",
    "共享（weights sharing)的方法来简化训练过程，每个样本所对应模型是部分权重共享的，只有被舍弃掉那部分权重不同。\n",
    "\n",
    "　　使用dropout可以使用使一个隐含结点不能与其它隐含结点完全协同合作，因此其它的隐含结点可能被舍弃，这样就不能通过所有的隐含结点共同作用训练出复杂的模型（只针对某一个训练样本），我们不能确定其它隐含结点此时是否被激活，这样\n",
    "\n",
    "就有效的防止了过拟合现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.如果只使用一个隐层，需要多少隐节点能够实现包含n元输入的任意布尔函数？\n",
    "> [参考](https://mp.weixin.qq.com/s/WGuKZZ2c9Keh94ANqYnGog)  \n",
    "> <font color=red>评分标准: 见答案<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n元布尔函数的析取范式最多包含2(n-1)个合取式，对于单隐层的MLP，需要2(n-1)个隐节点可以实现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
